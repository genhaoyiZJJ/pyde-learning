{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# 导⼊相关的⼯具包\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, activations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class Inception(tf.keras.Model):\n",
    "    # c1--c4是每条路径的输出通道数\n",
    "    def __init__(self, c1, c2, c3, c4):\n",
    "        super().__init__()\n",
    "        # 线路1，单1x1卷积层\n",
    "        self.p1_1 = tf.keras.layers.Conv2D(c1, 1, activation='relu')\n",
    "        # 线路2，1x1卷积层后接3x3卷积层\n",
    "        self.p2_1 = tf.keras.layers.Conv2D(c2[0], 1, activation='relu')\n",
    "        self.p2_2 = tf.keras.layers.Conv2D(c2[1], 3, padding='same',\n",
    "                                           activation='relu')\n",
    "        # 线路3，1x1卷积层后接5x5卷积层\n",
    "        self.p3_1 = tf.keras.layers.Conv2D(c3[0], 1, activation='relu')\n",
    "        self.p3_2 = tf.keras.layers.Conv2D(c3[1], 5, padding='same',\n",
    "                                           activation='relu')\n",
    "        # 线路4，3x3最大汇聚层后接1x1卷积层\n",
    "        self.p4_1 = tf.keras.layers.MaxPool2D(3, 1, padding='same')\n",
    "        self.p4_2 = tf.keras.layers.Conv2D(c4, 1, activation='relu')\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        p1 = self.p1_1(x)\n",
    "        p2 = self.p2_2(self.p2_1(x))\n",
    "        p3 = self.p3_2(self.p3_1(x))\n",
    "        p4 = self.p4_2(self.p4_1(x))\n",
    "        # 在通道维度上连结输出\n",
    "        return tf.keras.layers.Concatenate()([p1, p2, p3, p4])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def b1():\n",
    "    return tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(64, 7, strides=2, padding='same',\n",
    "                               activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def b2():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(64, 1, activation='relu'),\n",
    "        tf.keras.layers.Conv2D(192, 3, padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def b3():\n",
    "    return tf.keras.models.Sequential([\n",
    "        Inception(64, (96, 128), (16, 32), 32),\n",
    "        Inception(128, (128, 192), (32, 96), 64),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def b4():\n",
    "    return tf.keras.Sequential([\n",
    "        Inception(192, (96, 208), (16, 48), 64),\n",
    "        Inception(160, (112, 224), (24, 64), 64),\n",
    "        Inception(128, (128, 256), (24, 64), 64),\n",
    "        Inception(112, (144, 288), (32, 64), 64),\n",
    "        Inception(256, (160, 320), (32, 128), 128),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def b5():\n",
    "    return tf.keras.Sequential([\n",
    "        Inception(256, (160, 320), (32, 128), 128),\n",
    "        Inception(384, (192, 384), (48, 128), 128),\n",
    "        tf.keras.layers.GlobalAvgPool2D(),\n",
    "        tf.keras.layers.Flatten()\n",
    "    ])\n",
    "\n",
    "# “net”必须是一个将被传递给“d2l.train_ch6（）”的函数。\n",
    "# 为了利用我们现有的CPU/GPU设备，这样模型构建/编译需要在“strategy.scope()”\n",
    "def net():\n",
    "    return tf.keras.Sequential([b1(), b2(), b3(), b4(), b5(),\n",
    "                                tf.keras.layers.Dense(10)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t (1, 24, 24, 64)\n",
      "Sequential output shape:\t (1, 12, 12, 192)\n",
      "Sequential output shape:\t (1, 6, 6, 480)\n",
      "Sequential output shape:\t (1, 3, 3, 832)\n",
      "Sequential output shape:\t (1, 1024)\n",
      "Dense output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "X = tf.random.uniform(shape=(1, 96, 96, 1))\n",
    "for layer in net().layers:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, 'output shape:\\t', X.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}