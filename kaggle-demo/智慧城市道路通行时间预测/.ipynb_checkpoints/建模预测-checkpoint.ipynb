{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from ultis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取处理好的特征数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link_ID</th>\n",
       "      <th>date</th>\n",
       "      <th>time_interval_begin</th>\n",
       "      <th>travel_time</th>\n",
       "      <th>imputation1</th>\n",
       "      <th>lagging1</th>\n",
       "      <th>lagging2</th>\n",
       "      <th>lagging3</th>\n",
       "      <th>lagging4</th>\n",
       "      <th>lagging5</th>\n",
       "      <th>length</th>\n",
       "      <th>area</th>\n",
       "      <th>vacation</th>\n",
       "      <th>minute_series</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_week_en</th>\n",
       "      <th>hour_en</th>\n",
       "      <th>week_hour_1.0,1.0</th>\n",
       "      <th>week_hour_1.0,2.0</th>\n",
       "      <th>week_hour_1.0,3.0</th>\n",
       "      <th>week_hour_2.0,1.0</th>\n",
       "      <th>week_hour_2.0,2.0</th>\n",
       "      <th>week_hour_2.0,3.0</th>\n",
       "      <th>week_hour_3.0,1.0</th>\n",
       "      <th>week_hour_3.0,2.0</th>\n",
       "      <th>week_hour_3.0,3.0</th>\n",
       "      <th>links_num_2</th>\n",
       "      <th>links_num_3</th>\n",
       "      <th>links_num_4</th>\n",
       "      <th>links_num_5</th>\n",
       "      <th>width_3</th>\n",
       "      <th>width_6</th>\n",
       "      <th>width_9</th>\n",
       "      <th>width_12</th>\n",
       "      <th>width_15</th>\n",
       "      <th>link_ID_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:00:00</td>\n",
       "      <td>1.662360</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48</td>\n",
       "      <td>144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:02:00</td>\n",
       "      <td>1.681661</td>\n",
       "      <td>True</td>\n",
       "      <td>1.662360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48</td>\n",
       "      <td>144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:04:00</td>\n",
       "      <td>1.676155</td>\n",
       "      <td>True</td>\n",
       "      <td>1.681661</td>\n",
       "      <td>1.662360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48</td>\n",
       "      <td>144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:06:00</td>\n",
       "      <td>1.683786</td>\n",
       "      <td>True</td>\n",
       "      <td>1.676155</td>\n",
       "      <td>1.681661</td>\n",
       "      <td>1.662360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48</td>\n",
       "      <td>144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3377906280028510514</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>2017-03-01 06:08:00</td>\n",
       "      <td>1.683193</td>\n",
       "      <td>True</td>\n",
       "      <td>1.683786</td>\n",
       "      <td>1.676155</td>\n",
       "      <td>1.681661</td>\n",
       "      <td>1.66236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48</td>\n",
       "      <td>144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               link_ID        date time_interval_begin  travel_time  imputation1  lagging1  lagging2  lagging3  lagging4  lagging5  length  area  vacation  minute_series  day_of_week  day_of_week_en  hour_en  week_hour_1.0,1.0  week_hour_1.0,2.0  week_hour_1.0,3.0  week_hour_2.0,1.0  week_hour_2.0,2.0  week_hour_2.0,3.0  week_hour_3.0,1.0  week_hour_3.0,2.0  week_hour_3.0,3.0  links_num_2  links_num_3  links_num_4  links_num_5  width_3  width_6  width_9  width_12  width_15  link_ID_en\n",
       "0  3377906280028510514  2017-03-01 2017-03-01 06:00:00     1.662360         True       NaN       NaN       NaN       NaN       NaN      48   144       0.0            0.0            3             1.0      1.0                  1                  0                  0                  0                  0                  0                  0                  0                  0            1            0            0            0        1        0        0         0         0          47\n",
       "1  3377906280028510514  2017-03-01 2017-03-01 06:02:00     1.681661         True  1.662360       NaN       NaN       NaN       NaN      48   144       0.0            2.0            3             1.0      1.0                  1                  0                  0                  0                  0                  0                  0                  0                  0            1            0            0            0        1        0        0         0         0          47\n",
       "2  3377906280028510514  2017-03-01 2017-03-01 06:04:00     1.676155         True  1.681661  1.662360       NaN       NaN       NaN      48   144       0.0            4.0            3             1.0      1.0                  1                  0                  0                  0                  0                  0                  0                  0                  0            1            0            0            0        1        0        0         0         0          47\n",
       "3  3377906280028510514  2017-03-01 2017-03-01 06:06:00     1.683786         True  1.676155  1.681661  1.662360       NaN       NaN      48   144       0.0            6.0            3             1.0      1.0                  1                  0                  0                  0                  0                  0                  0                  0                  0            1            0            0            0        1        0        0         0         0          47\n",
       "4  3377906280028510514  2017-03-01 2017-03-01 06:08:00     1.683193         True  1.683786  1.676155  1.681661   1.66236       NaN      48   144       0.0            8.0            3             1.0      1.0                  1                  0                  0                  0                  0                  0                  0                  0                  0            1            0            0            0        1        0        0         0         0          47"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/training.txt', delimiter=';', parse_dates=['time_interval_begin'], dtype={'link_ID': object})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "时间序列特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lagging5', 'lagging4', 'lagging3', 'lagging2', 'lagging1']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lagging = 5\n",
    "lagging_feature = ['lagging%01d' % e for e in range(lagging, 0, -1)]\n",
    "lagging_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_feature = [x for x in df.columns.values.tolist() if x not in ['time_interval_begin', 'link_ID', 'link_ID_int',\n",
    "                                                                   'date', 'travel_time', 'imputation1',\n",
    "                                                                   'minute_series', 'area', 'hour_en', 'day_of_week']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_feature = [x for x in base_feature if x not in lagging_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['length', 'vacation', 'day_of_week_en', 'week_hour_1.0,1.0', 'week_hour_1.0,2.0', 'week_hour_1.0,3.0', 'week_hour_2.0,1.0', 'week_hour_2.0,2.0', 'week_hour_2.0,3.0', 'week_hour_3.0,1.0', 'week_hour_3.0,2.0', 'week_hour_3.0,3.0', 'links_num_2', 'links_num_3', 'links_num_4', 'links_num_5', 'width_3', 'width_6', 'width_9', 'width_12', 'width_15', 'link_ID_en', 'lagging5', 'lagging4', 'lagging3', 'lagging2', 'lagging1']\n"
     ]
    }
   ],
   "source": [
    "train_feature = list(base_feature)\n",
    "train_feature.extend(lagging_feature)\n",
    "valid_feature = list(base_feature)\n",
    "valid_feature.extend(['minute_series', 'travel_time'])\n",
    "print (train_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost训练参数：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_grid = {\n",
    "    'learning_rate': [0.05],\n",
    "    'n_estimators': [100],\n",
    "    'subsample': [0.6],\n",
    "    'colsample_bytree': [0.6],\n",
    "    'max_depth': [7],\n",
    "    'min_child_weight': [1],\n",
    "    'reg_alpha': [2],\n",
    "    'gamma': [0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = ParameterGrid(params_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_evaluate(df, df_test, params):\n",
    "    df = df.dropna()\n",
    "    X = df[train_feature].values\n",
    "    y = df['travel_time'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "    df_test = df_test[valid_feature].values\n",
    "    valid_data = bucket_data(df_test)\n",
    "\n",
    "    eval_set = [(X_test, y_test)]\n",
    "    regressor = xgb.XGBRegressor(learning_rate=params['learning_rate'], n_estimators=params['n_estimators'],\n",
    "                                 booster='gbtree', objective='reg:linear', n_jobs=-1, subsample=params['subsample'],\n",
    "                                 colsample_bytree=params['colsample_bytree'], random_state=0,\n",
    "                                 max_depth=params['max_depth'], gamma=params['gamma'],\n",
    "                                 min_child_weight=params['min_child_weight'], reg_alpha=params['reg_alpha'])\n",
    "    regressor.fit(X_train, y_train, verbose=False, early_stopping_rounds=10, eval_metric=mape_ln,\n",
    "                  eval_set=eval_set)\n",
    "    return regressor, cross_valid(regressor, valid_data,lagging=lagging), regressor.best_iteration, regressor.best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(df, params, best, vis=False):\n",
    "    train1 = df.loc[df['time_interval_begin'] <= pd.to_datetime('2017-03-24')]\n",
    "    train2 = df.loc[\n",
    "        (df['time_interval_begin'] > pd.to_datetime('2017-03-24')) & (\n",
    "            df['time_interval_begin'] <= pd.to_datetime('2017-04-18'))]\n",
    "    train3 = df.loc[\n",
    "        (df['time_interval_begin'] > pd.to_datetime('2017-04-18')) & (\n",
    "            df['time_interval_begin'] <= pd.to_datetime('2017-05-12'))]\n",
    "    train4 = df.loc[\n",
    "        (df['time_interval_begin'] > pd.to_datetime('2017-05-12')) & (\n",
    "            df['time_interval_begin'] <= pd.to_datetime('2017-06-06'))]\n",
    "    train5 = df.loc[\n",
    "        (df['time_interval_begin'] > pd.to_datetime('2017-06-06')) & (\n",
    "            df['time_interval_begin'] <= pd.to_datetime('2017-06-30'))]\n",
    "\n",
    "    regressor, loss1, best_iteration1, best_score1 = fit_evaluate(pd.concat([train1, train2, train3, train4]), train5,\n",
    "                                                                  params)\n",
    "    print (best_iteration1, best_score1, loss1)\n",
    "\n",
    "    regressor, loss2, best_iteration2, best_score2 = fit_evaluate(pd.concat([train1, train2, train3, train5]), train4,\n",
    "                                                                  params)\n",
    "    print (best_iteration2, best_score2, loss2)\n",
    "\n",
    "    regressor, loss3, best_iteration3, best_score3 = fit_evaluate(pd.concat([train1, train2, train4, train5]), train3,\n",
    "                                                                  params)\n",
    "    print (best_iteration3, best_score3, loss3)\n",
    "\n",
    "    regressor, loss4, best_iteration4, best_score4 = fit_evaluate(pd.concat([train1, train3, train4, train5]), train2,\n",
    "                                                                  params)\n",
    "    print (best_iteration4, best_score4, loss4)\n",
    "\n",
    "    regressor, loss5, best_iteration5, best_score5 = fit_evaluate(pd.concat([train2, train3, train4, train5]), train1,\n",
    "                                                                  params)\n",
    "    print (best_iteration5, best_score5, loss5)\n",
    "    \n",
    "    loss = [loss1, loss2, loss3, loss4, loss5]\n",
    "    params['loss_std'] = np.std(loss)\n",
    "    params['loss'] = str(loss)\n",
    "    params['mean_loss'] = np.mean(loss)\n",
    "    params['n_estimators'] = str([best_iteration1, best_iteration2, best_iteration3, best_iteration4, best_iteration5])\n",
    "    params['best_score'] = str([best_score1, best_score2, best_score3, best_score4, best_score5])\n",
    "    \n",
    "    print (str(params))\n",
    "    if np.mean(loss) <= best:\n",
    "        best = np.mean(loss)\n",
    "        print (\"best with: \" + str(params))\n",
    "        #feature_vis(regressor, train_feature)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 0.174535 0.09750734006537107\n",
      "99 0.149778 0.22697949568099954\n",
      "99 0.142421 0.26995488782745247\n",
      "99 0.141303 0.2782240572632962\n",
      "99 0.142115 0.2816868987204913\n",
      "{'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.05, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': '[86, 99, 99, 99, 99]', 'reg_alpha': 2, 'subsample': 0.6, 'loss_std': 0.06950270135557089, 'loss': '[0.09750734006537107, 0.22697949568099954, 0.26995488782745247, 0.2782240572632962, 0.2816868987204913]', 'mean_loss': 0.2308705359115221, 'best_score': '[0.174535, 0.149778, 0.142421, 0.141303, 0.142115]'}\n",
      "best with: {'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.05, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': '[86, 99, 99, 99, 99]', 'reg_alpha': 2, 'subsample': 0.6, 'loss_std': 0.06950270135557089, 'loss': '[0.09750734006537107, 0.22697949568099954, 0.26995488782745247, 0.2782240572632962, 0.2816868987204913]', 'mean_loss': 0.2308705359115221, 'best_score': '[0.174535, 0.149778, 0.142421, 0.141303, 0.142115]'}\n"
     ]
    }
   ],
   "source": [
    "best = 1\n",
    "for params in grid:\n",
    "    best = train(df, params, best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成预测序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit_params = {\n",
    "     'learning_rate': 0.05,\n",
    "     'n_estimators': 100,\n",
    "     'subsample': 0.6,\n",
    "     'colsample_bytree': 0.6,\n",
    "     'max_depth': 7,\n",
    "     'min_child_weight': 1,\n",
    "     'reg_alpha': 2,\n",
    "     'gamma': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgboost_submit(df, params):\n",
    "    train_df = df.loc[df['time_interval_begin'] < pd.to_datetime('2017-07-01')]\n",
    "\n",
    "    train_df = train_df.dropna()\n",
    "    X = train_df[train_feature].values\n",
    "    y = train_df['travel_time'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "    eval_set = [(X_test, y_test)]\n",
    "    regressor = xgb.XGBRegressor(learning_rate=params['learning_rate'], n_estimators=params['n_estimators'],\n",
    "                                 booster='gbtree', objective='reg:linear', n_jobs=-1, subsample=params['subsample'],\n",
    "                                 colsample_bytree=params['colsample_bytree'], random_state=0,\n",
    "                                 max_depth=params['max_depth'], gamma=params['gamma'],\n",
    "                                 min_child_weight=params['min_child_weight'], reg_alpha=params['reg_alpha'])\n",
    "    regressor.fit(X_train, y_train, verbose=True, early_stopping_rounds=10, eval_metric=mape_ln,\n",
    "                  eval_set=eval_set)\n",
    "    #feature_vis(regressor, train_feature)\n",
    "    joblib.dump(regressor, 'model/xgbr.pkl')\n",
    "    print (regressor)\n",
    "    submission(train_feature, regressor, df, 'submission/xgbr1.txt', 'submission/xgbr2.txt', 'submission/xgbr3.txt',\n",
    "               'submission/xgbr4.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError -529697949] Windows Error 0xe06d7363",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-418c2cac3b0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxgboost_submit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubmit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-ad76a90649e4>\u001b[0m in \u001b[0;36mxgboost_submit\u001b[1;34m(df, params)\u001b[0m\n\u001b[0;32m     15\u001b[0m                                  min_child_weight=params['min_child_weight'], reg_alpha=params['reg_alpha'])\n\u001b[0;32m     16\u001b[0m     regressor.fit(X_train, y_train, verbose=True, early_stopping_rounds=10, eval_metric=mape_ln,\n\u001b[1;32m---> 17\u001b[1;33m                   eval_set=eval_set)\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;31m#feature_vis(regressor, train_feature)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregressor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model/xgbr.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0meval_set\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m             evals = list(DMatrix(x[0], label=x[1], missing=self.missing,\n\u001b[1;32m--> 268\u001b[1;33m                                  nthread=self.n_jobs) for x in eval_set)\n\u001b[0m\u001b[0;32m    269\u001b[0m             evals = list(zip(evals, [\"validation_{}\".format(i) for i in\n\u001b[0;32m    270\u001b[0m                                      range(len(evals))]))\n",
      "\u001b[1;32me:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0meval_set\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m             evals = list(DMatrix(x[0], label=x[1], missing=self.missing,\n\u001b[1;32m--> 268\u001b[1;33m                                  nthread=self.n_jobs) for x in eval_set)\n\u001b[0m\u001b[0;32m    269\u001b[0m             evals = list(zip(evals, [\"validation_{}\".format(i) for i in\n\u001b[0;32m    270\u001b[0m                                      range(len(evals))]))\n",
      "\u001b[1;32me:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, label, missing, weight, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[0;32m    278\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_from_csc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_from_npy2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_init_from_npy2d\u001b[1;34m(self, mat, missing, nthread)\u001b[0m\n\u001b[0;32m    363\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_float\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m                 nthread))\n\u001b[0m\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError -529697949] Windows Error 0xe06d7363"
     ]
    }
   ],
   "source": [
    "xgboost_submit(df, submit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
